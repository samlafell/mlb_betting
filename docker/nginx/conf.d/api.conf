# MLB ML API Gateway Configuration

upstream fastapi_backend {
    server fastapi:8000;
    keepalive 8;
}

# Main API server
server {
    listen 80;
    server_name localhost;

    # Security
    limit_conn conn_limit_per_ip 10;
    
    # Client settings
    client_max_body_size 1M;
    client_body_timeout 30s;
    client_header_timeout 30s;

    # Health check endpoint (high rate limit)
    location /health {
        limit_req zone=health_limit burst=10 nodelay;
        proxy_pass http://fastapi_backend/health;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # Quick health check timeouts
        proxy_connect_timeout 5s;
        proxy_send_timeout 5s;
        proxy_read_timeout 5s;
    }

    # API v1 endpoints
    location /api/v1/ {
        limit_req zone=api_limit burst=20 nodelay;
        
        proxy_pass http://fastapi_backend/api/v1/;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # API timeouts
        proxy_connect_timeout 30s;
        proxy_send_timeout 30s;
        proxy_read_timeout 30s;
        
        # Add API-specific headers
        add_header X-API-Version "1.0" always;
        add_header Cache-Control "no-cache, no-store, must-revalidate" always;
    }

    # Prediction endpoints (stricter rate limiting)
    location /api/v1/predict {
        limit_req zone=prediction_limit burst=5 nodelay;
        
        proxy_pass http://fastapi_backend/api/v1/predict;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # Longer timeouts for ML inference
        proxy_connect_timeout 60s;
        proxy_send_timeout 60s;
        proxy_read_timeout 60s;
        
        # ML-specific headers
        add_header X-ML-Service "mlb-prediction" always;
    }

    # Batch prediction endpoints (very strict rate limiting)
    location /api/v1/predict/batch {
        limit_req zone=prediction_limit burst=2 nodelay;
        
        proxy_pass http://fastapi_backend/api/v1/predict/batch;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # Extended timeouts for batch processing
        proxy_connect_timeout 120s;
        proxy_send_timeout 120s;
        proxy_read_timeout 120s;
        
        # Increase body size for batch requests
        client_max_body_size 5M;
    }

    # Documentation (if enabled)
    location /docs {
        limit_req zone=api_limit burst=10 nodelay;
        proxy_pass http://fastapi_backend/docs;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }

    # OpenAPI schema
    location /openapi.json {
        limit_req zone=api_limit burst=5 nodelay;
        proxy_pass http://fastapi_backend/openapi.json;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # Cache OpenAPI schema
        add_header Cache-Control "public, max-age=300" always;
    }

    # Block all other requests
    location / {
        return 404 '{"error": "Not Found", "message": "This endpoint does not exist"}';
        add_header Content-Type application/json always;
    }

    # Error pages
    error_page 429 @rate_limit_error;
    error_page 502 503 504 @upstream_error;

    location @rate_limit_error {
        return 429 '{"error": "Rate Limited", "message": "Too many requests. Please slow down."}';
        add_header Content-Type application/json always;
        add_header Retry-After 60 always;
    }

    location @upstream_error {
        return 503 '{"error": "Service Unavailable", "message": "ML service is temporarily unavailable"}';
        add_header Content-Type application/json always;
        add_header Retry-After 30 always;
    }
}

# Future HTTPS configuration
# server {
#     listen 443 ssl http2;
#     server_name your-domain.com;
#     
#     ssl_certificate /etc/nginx/ssl/cert.pem;
#     ssl_certificate_key /etc/nginx/ssl/key.pem;
#     ssl_protocols TLSv1.2 TLSv1.3;
#     ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-GCM-SHA384;
#     ssl_prefer_server_ciphers off;
#     
#     # Include same location blocks as HTTP
# }